{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "为数据集中的每一个context构建一个query",
   "id": "aeb6342aadeba071"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T14:38:48.259138Z",
     "start_time": "2025-04-21T14:38:35.278032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from email.contentmanager import maintype\n",
    "from operator import index\n",
    "from llama_index.core.llms.dashscope\n",
    "import pandas as pd\n",
    "from langchain_community.chat_models import ChatTongyi\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.evaluation import generate_question_context_pairs\n",
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "\n",
    "from rag import retriever"
   ],
   "id": "ebac4b6576f729c2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人工智能生成内容_百度百科 网页新闻贴吧知道网盘图片视频地图文库资讯采购百科百度首页登录注册进入词条全站搜索帮助首页秒懂百科特色百科知识专题加入百科百科团队权威合作个人中心人工智能生成内容播报讨论上传视频人工智能生成内容(AIGC)收藏查看我的收藏0有用+10同义词AIGC（人工智能生成内容(AIGC)）一般指人工智能生成内容人工智能生成内容（Artificial Intelligence Generated Content）是人工智能1.0时代进入2.0时代的重要标志。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12935\\PycharmProjects\\rag_test\\rag.py:29: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  rag_embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-zh-v1.5\")\n",
      "D:\\Software\\miniconda3\\envs\\rag_test\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T14:39:59.068212Z",
     "start_time": "2025-04-21T14:39:58.895172Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = DashScope(model_name=DashScopeGenerationModels.QWEN_MAX)\n",
    "\n",
    "# Prompt to generate questions\n",
    "qa_generate_prompt_tmpl = \"\"\"\\\n",
    "Context information is below.\n",
    "\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "\n",
    "Given the context information and not prior knowledge.\n",
    "generate only questions based on the below query.\n",
    "\n",
    "You are a university professor. Your task is to set {num_questions_per_chunk} questions for the upcoming Chinese quiz.\n",
    "Questions throughout the test should be diverse. Questions should not contain options or start with Q1/Q2.\n",
    "Questions must be written in Chinese. The expression must be concise and clear.\n",
    "It should not exceed 15 Chinese characters. Words such as \"这\", \"那\", \"根据\", \"依据\" and other punctuation marks\n",
    "should not be used. Abbreviations may be used for titles and professional terms.\n",
    "\"\"\"\n",
    "##生成问题\n",
    "nodes = []\n",
    "data_df = pd.read_csv(\"../data/doc_qa_dataset.csv\",encoding=\"utf-8\")\n",
    "for i ,row in data_df.iterrows():\n",
    "    if len(row[\"content\"]) > 80 and i > 96:\n",
    "        node = TextNode(text=row[\"content\"])\n",
    "        node.id_ = f\"node_{i+1}\"\n",
    "        nodes.append(node)\n",
    "\n",
    "doc_qa_dataset = generate_question_context_pairs(nodes,llm=llm,num_questions_per_chunk=1,qa_generate_prompt_tmpl=qa_generate_prompt_tmpl)\n",
    "\n",
    "doc_qa_dataset.save_json(\"../data/doc_qa_dataset_test.json\")"
   ],
   "id": "b1b5758427d131d9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/321 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ChatTongyi' object has no attribute 'complete'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 29\u001B[0m\n\u001B[0;32m     26\u001B[0m         node\u001B[38;5;241m.\u001B[39mid_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnode_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     27\u001B[0m         nodes\u001B[38;5;241m.\u001B[39mappend(node)\n\u001B[1;32m---> 29\u001B[0m doc_qa_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_question_context_pairs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43mllm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mllm\u001B[49m\u001B[43m,\u001B[49m\u001B[43mnum_questions_per_chunk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mqa_generate_prompt_tmpl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mqa_generate_prompt_tmpl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m doc_qa_dataset\u001B[38;5;241m.\u001B[39msave_json(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data/doc_qa_dataset_test.json\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\Software\\miniconda3\\envs\\rag_test\\lib\\site-packages\\llama_index\\core\\llama_dataset\\legacy\\embedding.py:90\u001B[0m, in \u001B[0;36mgenerate_qa_embedding_pairs\u001B[1;34m(nodes, llm, qa_generate_prompt_tmpl, num_questions_per_chunk)\u001B[0m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m node_id, text \u001B[38;5;129;01min\u001B[39;00m tqdm(node_dict\u001B[38;5;241m.\u001B[39mitems()):\n\u001B[0;32m     87\u001B[0m     query \u001B[38;5;241m=\u001B[39m qa_generate_prompt_tmpl\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m     88\u001B[0m         context_str\u001B[38;5;241m=\u001B[39mtext, num_questions_per_chunk\u001B[38;5;241m=\u001B[39mnum_questions_per_chunk\n\u001B[0;32m     89\u001B[0m     )\n\u001B[1;32m---> 90\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mllm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcomplete\u001B[49m(query)\n\u001B[0;32m     92\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(response)\u001B[38;5;241m.\u001B[39mstrip()\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     93\u001B[0m     questions \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     94\u001B[0m         re\u001B[38;5;241m.\u001B[39msub(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m^\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124md+[\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m).\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124ms]\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m, question)\u001B[38;5;241m.\u001B[39mstrip() \u001B[38;5;28;01mfor\u001B[39;00m question \u001B[38;5;129;01min\u001B[39;00m result\n\u001B[0;32m     95\u001B[0m     ]\n",
      "File \u001B[1;32mD:\\Software\\miniconda3\\envs\\rag_test\\lib\\site-packages\\pydantic\\main.py:994\u001B[0m, in \u001B[0;36mBaseModel.__getattr__\u001B[1;34m(self, item)\u001B[0m\n\u001B[0;32m    991\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__getattribute__\u001B[39m(item)  \u001B[38;5;66;03m# Raises AttributeError if appropriate\u001B[39;00m\n\u001B[0;32m    992\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    993\u001B[0m     \u001B[38;5;66;03m# this is the current error\u001B[39;00m\n\u001B[1;32m--> 994\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mitem\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'ChatTongyi' object has no attribute 'complete'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "BM25",
   "id": "26d3dc8c64e62e23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6b98a4978ceb278f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
